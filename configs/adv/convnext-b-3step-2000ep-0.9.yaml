
output_dir: $GCS_MODEL_DIR
name: conv-next-b-128-3step-2000ep
project: deit3-jax
steps: 1281167
training_epoch: 2000
warmup_epoch: 20
log_interval: 100
eval_epoch: 10
#resume: True

dataset:
  train_batch_size: 4096
  valid_batch_size: 2048
  train_loader_workers: 20
  valid_loader_workers: 10
  train_dataset_shards: "$GCS_DATASET_DIR/imagenet-1k-wds/imagenet1k-train-{0000..1023}.tar"
  valid_dataset_shards: "$GCS_DATASET_DIR/imagenet-1k-wds/imagenet1k-validation-{00..63}.tar"
  random_crop: src
  color_jitter: 0.0
  auto_augment: "none"
  random_erasing: 0.0
  augment_repeats: 3
  test_crop_ratio: 0.875
  shuffle_seed: 1
  image_size: 128
  dataset_mix_ratio: 0.9


train_state:
  train_module:
    target: 'train_modules.TrainAdvModule'
    mixup: 0.8
    cutmix: 1.0
    criterion: ce
    label_smoothing: 0.1
    train_adv_step: 3
    train_adv_step_size: 4/3 / 255


  model:
    target: 'models.ConvNeXt'
    model_kwargs:
      labels: 1000
      depths: [3,3,27,3]
      dims: [128, 256, 512, 1024]
      drop_path_rate: 0.0
#      ls_init_value: null

  optimizer:
    target: 'adamw'
    optimizer_kwargs:
      learning_rate: 0.004
      weight_decay: 0.05
      b1: 0.9
      b2: 0.999
#      eps: 1.0e-8
#      lr_decay: 1.0
#      clip_grad: 0.0

  init_seed: 1
  mixup_seed: 1
  dropout_seed: 1
  ema_decay: 0.9998






#    --init-seed 1 \
#    --grad-accum 1 \
#    --warmup-steps $((1281167 * 5 / $TRAIN_BATCH_SIZE)) \
#    --training-steps $((1281167 * 300 / $TRAIN_BATCH_SIZE)) \
#    --log-interval 100 \
#    --eval-interval $((1281167 * 10 / $TRAIN_BATCH_SIZE)) \
#    --project deit3-jax \
#    --name $(basename $0 .sh) \
#    --ipaddr $(curl -s ifconfig.me) \
#    --hostname $(hostname)
