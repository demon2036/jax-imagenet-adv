
output_dir: $GCS_MODEL_DIR
name: conv-next-b-128-3step-2000ep-ft
project: deit3-jax
steps: 1281167
training_epoch: 30
warmup_epoch: 0
log_interval: 100
eval_epoch: 5

dataset:
  train_batch_size: 2048
  valid_batch_size: 2048
  train_loader_workers: 20
  valid_loader_workers: 10
  train_dataset_shards: "$GCS_DATASET_DIR/imagenet-1k-wds/imagenet1k-train-{0000..1023}.tar"
  valid_dataset_shards: "$GCS_DATASET_DIR/imagenet-1k-wds/imagenet1k-validation-{00..63}.tar"
  random_crop: rrc
  color_jitter: 0.0
  auto_augment: "rand-m9-mstd0.5-inc1"
  random_erasing: 0.25
  augment_repeats: 3
  test_crop_ratio: 0.875
  shuffle_seed: 1
  image_size: 224
  dataset_mix_ratio: 0.0


train_state:
  train_module:
    target: 'train_modules.TrainAdvModule'
    mixup: 0.8
    cutmix: 1.0
    criterion: ce
    label_smoothing: 0.1
    train_adv_step:  3
    train_adv_step_size:  4/3 / 255


  model:
    target: 'models.ConvNeXt'
    model_kwargs:
      labels: 1000
      depths: [3,3,27,3]
      dims: [128, 256, 512, 1024]
      drop_path_rate: 0.0
#      ls_init_value: null

  optimizer:
    target: 'adamw'
    optimizer_kwargs:
      learning_rate: 2.0e-4
      weight_decay: 1.0e-8
      b1: 0.9
      b2: 0.999
#      eps: 1.0e-8
#      lr_decay: 1.0
#      clip_grad: 0.0

  init_seed: 1
  mixup_seed: 1
  dropout_seed: 1
  pretrained_ckpt: 'gs://brid-center-2b/conv-next-b-128-3step-2000ep-ema'
  ema_decay: 0.9998





#    --init-seed 1 \
#    --grad-accum 1 \
#    --warmup-steps $((1281167 * 5 / $TRAIN_BATCH_SIZE)) \
#    --training-steps $((1281167 * 300 / $TRAIN_BATCH_SIZE)) \
#    --log-interval 100 \
#    --eval-interval $((1281167 * 10 / $TRAIN_BATCH_SIZE)) \
#    --project deit3-jax \
#    --name $(basename $0 .sh) \
#    --ipaddr $(curl -s ifconfig.me) \
#    --hostname $(hostname)
